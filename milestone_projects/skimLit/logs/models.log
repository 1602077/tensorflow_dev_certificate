--------------------------------------------------
  Model0_TF-IDF-Multinomial-Naive-Bayes
--------------------------------------------------
Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])

Baseline Model Results
{ 'accuracy': 72.1832384482987,
  'f1': 0.6989250353450294,
  'precision': 0.7186466952323352,
  'recall': 0.7218323844829869}

--------------------------------------------------
  Preparing data for deep learning
--------------------------------------------------
Average length of each sentence: 26.34
Most sentences are around ~25 words long.
95% percentile sentence length: 55
Maximum sentence length in training set: 296

--------------------------------------------------
  Model1_Conv_1D
--------------------------------------------------

--------------------------------------------------
  Model2_USE_FeatExtr
--------------------------------------------------
Random sentence: the primary outcome was patient preference for the right or left side of the scar @ months postoperatively and modeled by polytomous logistic regression .
Sentence after embedding (first 30 values only):
 [-0.03727122 -0.05369774 -0.07764339  0.02533635 -0.04245052 -0.04172245
 -0.03965311 -0.01069881  0.08100656  0.02295269  0.07502592 -0.03678549
 -0.02767415  0.01133581 -0.06010926 -0.01224322 -0.07053725 -0.02755812
 -0.02126325  0.0624686   0.05993798  0.07666321 -0.00253137  0.01510441
  0.07382768  0.07419283  0.03464276  0.03754175 -0.04456692  0.00628303]

Length of sentence embedding: 512
Model: "Model2_USE_FeatExtr"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None,)]                 0         
_________________________________________________________________
universal_sentence_encoder ( (None, 512)               256797824 
_________________________________________________________________
dense_1 (Dense)              (None, 128)               65664     
_________________________________________________________________
dense_2 (Dense)              (None, 5)                 645       
=================================================================
Total params: 256,864,133
Trainable params: 66,309
Non-trainable params: 256,797,824
_________________________________________________________________

--------------------------------------------------
  Creating character embeddings
--------------------------------------------------
Average character length: 149.3662574983337
Sequence length which covers 95% of sentences: 290
Possible characters: abcdefghijklmnopqrstuvwxyz0123456789!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~
Number of chars in vocab: 28
Top 5 chars: ['', '[UNK]', 'e', 't', 'i']
Bottom 5 chars: ['k', 'x', 'z', 'q', 'j']

--------------------------------------------------
  Model3_Conv1D_CharEmbed
--------------------------------------------------
Model: "Model3_Conv1D_CharEmbed"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 1)]               0         
_________________________________________________________________
char_vectoriser (TextVectori (None, 55)                0         
_________________________________________________________________
char_embed (Embedding)       (None, 55, 25)            700       
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 55, 64)            8064      
_________________________________________________________________
global_max_pooling1d (Global (None, 64)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 325       
=================================================================
Total params: 9,089
Trainable params: 9,089
Non-trainable params: 0
_________________________________________________________________

--------------------------------------------------
  Model4_TokenAndCharEmbed
--------------------------------------------------
Model: "Model4_TokenAndCharEmbed"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_input (InputLayer)         [(None, 1)]          0                                            
__________________________________________________________________________________________________
token_inputs (InputLayer)       [(None,)]            0                                            
__________________________________________________________________________________________________
char_vectoriser (TextVectorizat (None, 55)           0           char_input[0][0]                 
__________________________________________________________________________________________________
universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               
__________________________________________________________________________________________________
char_embed (Embedding)          (None, 55, 25)       700         char_vectoriser[1][0]            
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 128)          65664       universal_sentence_encoder[1][0] 
__________________________________________________________________________________________________
bidirectional (Bidirectional)   (None, 48)           9600        char_embed[1][0]                 
__________________________________________________________________________________________________
token_char_hybrid (Concatenate) (None, 176)          0           dense_4[0][0]                    
                                                                 bidirectional[0][0]              
__________________________________________________________________________________________________
dropout (Dropout)               (None, 176)          0           token_char_hybrid[0][0]          
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 128)          22656       dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 5)            645         dropout_1[0][0]                  
==================================================================================================
Total params: 256,897,089
Trainable params: 99,265
Non-trainable params: 256,797,824
__________________________________________________________________________________________________
Check prefetch train and token datasets
<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>
<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>

--------------------------------------------------
  Model5_Tri_Embed_Model
--------------------------------------------------
Number of different line numbers
Train line numbers one-hot [:10]:
[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
Shape: (180040, 15)
Length coverage 95% of total_lienes: 18.0
Train total line numbers one-hot [:10]:
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]
Shape: (180040, 20)
Model: "Model5_Tri_Embed_Model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
char_inputs (InputLayer)        [(None, 1)]          0                                            
__________________________________________________________________________________________________
token_inputs (InputLayer)       [(None,)]            0                                            
__________________________________________________________________________________________________
char_vectoriser (TextVectorizat (None, 55)           0           char_inputs[0][0]                
__________________________________________________________________________________________________
universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               
__________________________________________________________________________________________________
char_embed (Embedding)          (None, 55, 25)       700         char_vectoriser[2][0]            
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 128)          65664       universal_sentence_encoder[2][0] 
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 48)           9600        char_embed[2][0]                 
__________________________________________________________________________________________________
M5_char_token_hybrid_embedding  (None, 176)          0           dense_7[0][0]                    
                                                                 bidirectional_1[0][0]            
__________________________________________________________________________________________________
line_num_inputs (InputLayer)    [(None, 15)]         0                                            
__________________________________________________________________________________________________
total_num_inputs (InputLayer)   [(None, 20)]         0                                            
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 256)          45312       M5_char_token_hybrid_embedding[0]
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 32)           512         line_num_inputs[0][0]            
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 32)           672         total_num_inputs[0][0]           
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           dense_10[0][0]                   
__________________________________________________________________________________________________
M5_char_token_pos_embed (Concat (None, 320)          0           dense_8[0][0]                    
                                                                 dense_9[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
output_layer (Dense)            (None, 5)            1605        M5_char_token_pos_embed[0][0]    
==================================================================================================
Total params: 256,921,889
Trainable params: 124,065
Non-trainable params: 256,797,824
_______________________________________________________________________________________Epoch 2/3
562/562 - 99s - loss: 0.9779 - accuracy: 0.8072 - val_loss: 0.9629 - val_accuracy: 0.8135
Epoch 3/3
562/562 - 1731s - loss: 0.9593 - accuracy: 0.8168 - val_loss: 0.9476 - val_accuracy: 0.8221

Model 5 Results:
{'accuracy': 82.55660002647954,
 'f1': 0.8245004522431233,
 'precision': 0.823945781208971,
 'recall': 0.8255660002647954}
y': 82.74195683834238,
 'f1': 0.8265216650858198,
 'precision': 0.8259664884398388,
 'recall': 0.8274195683834238}
